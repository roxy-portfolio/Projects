## â–¶ï¸Ž Bellabeat Data Analysis Case Study using R 

In this case study, I was asked to focus on one of the Bellabeat's products and analyze smart device data to gain insight 
into how consumers are using their smart devices. These insights will then help guide the marketing strategy for the company. 

To analyze the data, I will use R to perform summary statistics and create data visualizations.

## â–¶ï¸Ž About Bellabeat

Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the
global smart device market. UrÅ¡ka SrÅ¡en, cofounder and Chief Creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. 

### â–¶ï¸Ž Questions for the analysis:

1. What are some trends in smart device usage? 
2. How could these trends apply to Bellabeat customers? 
3. How could these trends help influence Bellabeat marketing strategy

### â–¶ï¸Ž Business Task

Identify potential opportunities for growth and recommendations for the Bellabeat marketing strategy improvement based on trends in smart device usage.

### â–¶ï¸Ž Dataset Source
FitBit Fitness Tracker Data, dataset made available through [Mobius](https://www.kaggle.com/datasets/arashnic/fitbit) (CC0: Public Domain)

### â–¶ï¸Ž About the Dataset
This dataset generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. Individual reports can be parsed by export session ID (column A) or timestamp (column B). Variation between output represents use of different types of Fitbit trackers and individual tracking behaviors / preferences.

#### âœ… Install and load R packages
Start by installing and load the required packages.

```{r loading packages}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(tidyr)
library(skimr)
library(janitor)
```

### âœ… Import data
```{r importing datasets}
daily_activity <- read_csv("mturkfitbit_export_3.12.16-4.11.16/Fitabase Data 3.12.16-4.11.16/dailyActivity_merged.csv")
intensities <- read_csv("mturkfitbit_export_3.12.16-4.11.16/Fitabase Data 3.12.16-4.11.16/dailyIntensities_merged.csv")
sleep <- read_csv("mturkfitbit_export_3.12.16-4.11.16/Fitabase Data 3.12.16-4.11.16/sleepDay_merged.csv")
weight_login <- read_csv("mturkfitbit_export_3.12.16-4.11.16/Fitabase Data 3.12.16-4.11.16/weightLogInfo_merged.csv")
```
### âœ…  Initial Data Inspection
Conduct an initial inspection to understand the structure and summary statistics of the data.


```{r observe datasets}
head(daily_activity)
```

<img width="870" alt="Screenshot 2024-08-01 at 12 41 43â€¯AM" src="https://github.com/user-attachments/assets/710aae0b-c193-4e1a-88fa-a1d10e1748ae">



```{r}
head(intensities)
```
<img width="857" alt="Screenshot 2024-08-01 at 12 43 05â€¯AM" src="https://github.com/user-attachments/assets/b054aefd-9470-459f-b971-3853756e98e7">





```{r}
head(sleep)
```
<img width="862" alt="Screenshot 2024-08-01 at 12 44 35â€¯AM" src="https://github.com/user-attachments/assets/7d809e06-7649-4adf-8e20-23c8f5a746f5">



```{r}
head(weight_login)
```
<img width="856" alt="Screenshot 2024-08-01 at 12 45 54â€¯AM" src="https://github.com/user-attachments/assets/4be37cd2-c080-40b9-b4bb-95628738a86f">



ðŸ”¹ Counting the unique users

```{r count the unique users}
n_distinct(daily_activity$Id) 
n_distinct(intensities$Id)
n_distinct(sleep$Id)
n_distinct(weight_login$Id)
```

This information tells us about number participants in each data sets.

33 participants - daily activity and intensities
24 participants - sleep 
8 participants - weight login 


### âœ… Documentation of Data Cleaning and Manipulation
This section details the data cleaning and manipulation processes performed on the Bellabeat dataset. Each step is documented to ensure transparency, reproducibility, and understanding of the changes made.

ðŸ”¹ Convert datetime to date format

```{r convert datetime to date format}
sleep_new <- sleep %>%
mutate(SleepDay = as.Date(SleepDay, format = "%m/%d/%Y")) %>% 
rename(Date = SleepDay) 
```

```{r}
head(sleep_new)
```
<img width="858" alt="Screenshot 2024-08-01 at 12 50 02â€¯AM" src="https://github.com/user-attachments/assets/3972bae3-bd05-4639-a329-69cf4130090b">




```{r}
daily_activity_new <- daily_activity %>%
mutate(ActivityDate = as.Date(ActivityDate, format = "%m/%d/%Y")) %>% 
rename(Date = ActivityDate) 
```

```{r}
head(daily_activity_new)
```
<img width="857" alt="Screenshot 2024-08-01 at 12 50 56â€¯AM" src="https://github.com/user-attachments/assets/417326e7-2610-421d-8b89-82e52f7c56b1">


ðŸ”¹ Merging Two Datasets

```{r Merging two datasets}
activity_summary <- merge(daily_activity_new, sleep_new, by = c("Id", "Date", "TotalSteps", "TotalDistance", "Calories", "TotalMinutesAsleep"))
```

```{r}
head(activity_summary)
```
<img width="1184" alt="Screenshot 2024-08-01 at 12 53 15â€¯AM" src="https://github.com/user-attachments/assets/b56f9995-f9de-454f-a531-146186f24d62">



```{r Count the users who have both daily activity and sleep records}
n_distinct(activity_summary$Id)
```


### **Removing Duplicates**
Check for and remove any duplicate records to avoid skewing the analysis.


Quick summary statistics we'd want to know about each data frame

```{r summary }
activity_summary %>%
select(TotalSteps,TotalDistance,Calories, TotalMinutesAsleep) %>%
summary()
```

```{r summary of sleeping pattern data}
activity_summary %>%
select(TotalSleepRecords, TotalMinutesAsleep, TotalTimeInBed) %>%
summary()
```
```{r summary of intensities}
intensities %>%
select(SedentaryMinutes, LightlyActiveMinutes, FairlyActiveMinutes, VeryActiveMinutes, SedentaryActiveDistance, LightActiveDistance, ModeratelyActiveDistance, VeryActiveDistance) %>%
summary()
```
The data cleaning and manipulation process ensures the dataset's integrity, consistency, and readiness for analysis. Each step is carefully documented, providing a clear trail of the modifications made to the original dataset. This comprehensive approach guarantees that the analysis will be based on clean, reliable data, leading to accurate and insightful results.
